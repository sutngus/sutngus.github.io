---
layout: post
title:  "5. 트리 알고리즘"
date : 2024-08-17 00:25:20 +0700
---

# 5-1 결정트리      
입고된 와인의 표시(화이트/ 레드)가 누락되었다. 알코올 도수 당도, pH 값으로 와인의 종류를 구별해보자      
먼저 **로지스틱 회귀모델**을 적용해보자.      
![image](https://github.com/user-attachments/assets/9fd637a9-3780-4416-9691-507ddc230a38)      
- 판다스 데이터프레임의 유용한 메서드: **info()**: 각 열의 데이터 타입과 누락된 데이터 확인/ **describe()**: 열에 대한 간략한 통계      
![image](https://github.com/user-attachments/assets/2edceb19-d4cc-4d93-85ec-e4c6e422cab4)      
- 1) 데이터프레임을 넘파이배열로 바꾸고, 2) 훈련세트와 테스트세트로 나누고, 3) 사이킷런의 StandardScaler 클래스를 이용해 특성들을 표준화해 스케일을 맞추어준다.      
![image](https://github.com/user-attachments/assets/c4b0e997-3b32-4da6-9732-938c4c6b7836)      
- 4) 로지스틱 회귀 모델 훈련 - 과소적합       
![image](https://github.com/user-attachments/assets/9b4f1b43-444d-48a2-9797-21851c07bdb5)      
![image](https://github.com/user-attachments/assets/92f0a89f-19dc-48eb-b39d-68b26b96ea05)      
우리는 모델이 왜 저런 계수 값을 학습했는지 정확히 이해하기 어려움 ---> 쉽게 설명할 수 있는 모델 = **결정트리**      

## 결정트리      
**결정트리**: 예/ 아니오 에 대한 질문을 이어나가면서 정답을 찾아 학습하는 알고리즘. 예측과정을 이해하기 쉽고 성능도 뛰어남      
```python
from sklearn.tree import DecisionTreeClassifier
dt = DecisionTreeClassifier(random_state=42)
dt.fit(train_scaled, train_target)
print(dt.score(train_scaled, train_target))
print(dt.score(test_scaled, test_target))
```
```python
import matplotlib.pyplot as plt
from sklearn.tree import plot_tree
plt.figure(figsize=(10,7))
plot_tree(dt)
plt.show()
```
![image](https://github.com/user-attachments/assets/3c881417-7e01-4b86-9a3d-a02cbe5d1713)      
너무 복잡하니 트리의 깊이를 제한해서 출력해보자.       
- max_depth: 트리가 성장할 최대 깊이, filled: 클래스에 따른 노드의 색(어떤 클래스의 비율이 높아지면 점점 진한 색이 됨), feature_name: 특성의 이름 전달      
```python
plt.figure(figsize=(10,7))
plot_tree(dt, max_depth=1, filled=True, feature_names=['alcohol', 'sugar', 'pH'])
plt.show()
```
![image](https://github.com/user-attachments/assets/336c8409-58d9-4c5e-b602-5205e64e912a)
![image](https://github.com/user-attachments/assets/ae51756f-40d9-4b7e-a182-d77c4fcd3a91)       
- value에서 왼쪽이 음성클래스, 오른쪽이 양성클래스      
- 리프노드에서 가장 많은 클래스가 예측 클래스가 됨      

### 불순도      
**불순도**: 얼마나 다양한 클래스가 섞여 있는지, 결정트리가 최적의 질문을 찾기 위한 기준, 데이터를 분할할 기준 - 지니불순도, 엔트로피불순도      
- DecisionTreeClassifier 클래스의 criterion 매개변수의 기본 값이 'gini'임      
- 지니불순도 = 1- (음성클래스의 비율^2 + 양성클래스의 비율^2)      
- 두 개의 클래스가 완전히 섞여 있다면 불순도가 높음. 두 클래스의 비율이 정확히 1/2씩 이라면 지니불순도가 0.5가 되어 최악임(최댓값). 순수노드는 0임      
- 부모노드와 자식노드의 불순도 차이(**정보이득**)가 가능한 크도록, 즉 자식노드의 불순도를 최대한 낮아지게 하도록 트리를 성장시킴     
- **정보이득**(불순도 차이) = 부모의 불순도 - (왼쪽노드 샘플 수/부모의 샘플 수)x왼쪽노드 불순도 - (오른쪽노드 샘플 수/부모의 샘플 수)x오른쪽노드 불순도       
- 엔트로피 불순도 = -음성클래스의 비율xlog2(음성클래스의 비율) - 양성클래스의 비율xlog2(양성클래스의 비율)      
- 지니 불순도와 엔트로피 불순도가 만든 결과의 차이는 크지 않음      
- 이렇듯 불순도를 기준으로 샘플을 나누고, 불순도는 클래스별 비율을 가지고 계산한다. 따라서 특성값의 스케일은 계산에 영향을 미치지 않기 때문에, **결정트리는 표준화 전처리 과정이 필요없다**. -> 전처리 전의 훈련세트와 테스트세트로 모델을 훈련시키면 score점수가 동일하게 나온다.      

### 가지치기      
- 결정트리는 제한 없이 성장하면 훈련세트에 과대적합되기 쉽기 때문에 **가지치기**로 결정트리의 성장을 제한해주어야함      
- 가장 간단한 방법은 최대 깊이(max_depth)를 정하는 것      
```python
dt = DecisionTreeClassifier(max_depth=3, random_state=42)
dt.fit(train_input, train_target)
print(dt.score(train_input, train_target))
print(dt.score(test_input, test_target))
```
- **특성중요도**: 결정트리에 사용된 특성이 불순도를 감소하는데 기여한 정도를 나타내는 값      
- 각 노드의 정보이득과 전체 샘플에 대한 비율을 곱한 후 특성별로 더하여 계산      
- 이를 활용하여 결정트리모델을 특성 선택에 활용할 수 있음      
```python
print(dt.feature_importances_)
``` 


# 5-2 교차검증과 그리드 서치      
화이트와인과 레드와인의 **분류 성능**을 올리기 위해서는 **다양한 하이퍼파라미터**를 시도해보아야한다.       
하지만 이 과정에서 테스트세트를 사용하면 테스트세트에 맞춰 모델을 훈련하는 꼴이다.       
따라서 성능을 올바르게 예측하기 위해서는, 테스트세트는 최종모델을 선택할 때까지 사용하지 말아야 한다.       

### 검증세트      
테스트세트를 사용하지 않고 모델을 평가하기 위해 훈련세트에서 떼어낸 세트를 **검증세트**라고 한다.      
![image](https://github.com/user-attachments/assets/47135bd2-bad0-4018-86d0-34b6018b85bb)      
- 훈련세트에서 모델을 훈련하고, 검증세트로 모델을 평가 -> 매개변수를 바꿔가며 가장 좋은 모델 선택      
- 이 매개변수를 사용해 전체 훈련 데이터에서 모델을 다시 훈련 -> 테스트 세트에서 최종 점수 평가      
검증세트를 만들어보자      
```python
import pandas as pd
wine = pd.read_csv('https://bit.ly/wine_csv_data')

data = wine[['alcohol', 'sugar', 'pH']].to_numpy()
target = wine['class'].to_numpy()

from sklearn.model_selection import train_test_split
train_input, test_input, train_target, test_target = train_test_split(
    data, target, test_size=0.2, random_state=42)
sub_input, val_input, sub_target, val_target = train_test_split(
    train_input, train_target, test_size=0.2, random_state=42)
print(sub_input.shape, val_input.shape)
# train_test_split() 함수를 2번 적용해서 훈련세트와 검증세트로 나누어줌

from sklearn.tree import DecisionTreeClassifier
dt = DecisionTreeClassifier(random_state=42)
dt.fit(sub_input, sub_target)
print(dt.score(sub_input, sub_target))
print(dt.score(val_input, val_target))
```
### 교차검증      
하지만 검증세트가 크지 않다면 데이터를 나누는 기준에 따라 검증 점수가 들쭉날쭉할 것이다.       
따라서 모델성능을 안정적으로 평가하기 위해 검증세트를 여러번(k번) 나누어 모델을 여러 번 평가해야한다. 그를 **k-겹 교차검증**이라고 한다.      
훈련세트를 여러 폴드로 나눈 다음, 한 폴드씩 돌아가면서 검증세트의 역할을 하고 나머지 폴드로 모델을 훈련한다.        
**최종 점수**는 모든 폴드의 검증점수를 평균하여 계산한다.       
![image](https://github.com/user-attachments/assets/2fb0e8b3-a34c-48ff-a8f2-bd54217eb856)      
```python
from sklearn.model_selection import cross_validate
scores = cross_validate(dt, train_input, train_target)
print(scores)
```
![image](https://github.com/user-attachments/assets/db6c04f8-c1ec-4725-9eff-1b5d93108a2e)      
- 사이킷런 cross_validate() 교차검증함수에 평가할 모델 객체를 첫 번째 매개변수로 전달, 직접 검증세트를 떼어내지 않고 훈련세트 전체를 cross_validate()함수에 전달      
- fit_time, score_time, test_score 키를 가진 딕셔너리 반환 - test_score의 점수(검증폴드의 점수)를 평균한 것이 **교차검증의 최종점수** - print(np.mean(scores['test_score']))      
- 주의할 점) cross_validate()는 훈련세트를 섞어 폴드를 나누지 않기 때문에, 교차검증을 할 때 훈련세트를 섞으려면 **분할기**를 지정해야함 - cv      
- **분할기**는 교차검증에서 폴드를 어떻게 나눌지 결정해줌(데이터를 섞지 않고, 클래스 비율을 유지하며 폴드를 나눔, 만약 데이터를 섞고 싶다면 shuffle=True로 설정해야함) - 회귀: KFold 분할기, 분류: StratifiedKFold 사용      
```python
from sklearn.model_selection import StratifiedKFold
scores = cross_validate(dt, train_input, train_target, cv=StratifiedKFold())
print(np.mean(scores['test_score']))
```
만약, 훈련세트를 섞은 후 10-폴드 교차검증을 수행하려면,       
```python
splitter = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)
scores = cross_validate(dt, train_input, train_target, cv=splitter)
print(np.mean(scores['test_score']))
```

이어서 매개변수 값을 바꿔가면서 가장 좋은 성능이 나오는 모델을 찾아보자      
- 모델파라미터: 머신러닝모델이 학습하는 파라미터      
- 하이퍼파라미터: 모델이 학습할 수 없어서 (학습 시작 전에) 사용자가 지정해야만 하는 파라미터      
- 하이퍼파라미터 튜닝하는 법: 라이브러리가 제공하는 기본값 그대로 모델 훈련 - 최적의 하이퍼파라미터를 찾기위해, 검증세트의 점수나 교차검증을 통해서 매개변수를 바꿔줌- 매개변수를 바꿔가면서 모델을 훈련하고 교차검증 수행      
- 여러개의 매개변수를 튜닝할 때, 하나씩 하는 게 아니라 동시에 진행해주어야 함      

Q. 사람들은 하이퍼파라미터를 수동으로 설정하지말고, 그를 최적으로 지정해주는 autoML을 그냥 사용하면 되는거 아닌가?      
A. AutoML은 매우 유용한 도구이지만, 모든 경우에 이상적인 해결책은 아닙니다. 특히 복잡하거나 특화된 문제, 제한된 자원, 해석 가능성이 중요한 경우, 수동으로 하이퍼파라미터를 조정하는 것이 더 적합할 수 있습니다. AutoML은 반복적이고 표준화된 작업을 빠르게 처리하는 데 강력하지만, 전문 지식이 요구되는 상황에서는 수동 조정이 여전히 필요합니다.      

다양한 하이퍼파라미터를 탐색과 교차검증을 자동화하는 도구인 **그리드서치**를 이용하면 편하다.- cross_validate() 함수를 호출할 필요가 없다. 탐색할 매개변수를 나열하면, 교차검증을 수행하여 가장 좋은 검증 점수의 매개변수 조합을 선택한 후, 이 매개변수 조합으로 최종 모델을 훈련한다.       
```python
from sklearn.model_selection import GridSearchCV
params = {'min_impurity_decrease': [0.0001, 0.0002, 0.0003, 0.0004, 0.0005]} # {탐색할 매개변수: 탐색할 값의 리스트}

gs = GridSearchCV(DecisionTreeClassifier(random_state=42), params, n_jobs=-1) # 객체 생성
# GridSearchCV의 cv 매개변수 기본값은 5임. min_impurity_decrease 값마다 5폴드교차검증을 수행하므로, 5x5=25개의 모델을 훈련함
# 많은 모델을 훈련하므로 n_jobs매개변수에서 병렬실행에 사용할 CPU코어 수를 지정해주어야함. -1로 지정하면 시스템에 있는 모든 코어를 사용함

gs.fit(train_input, train_target)
# 그리드 서치는 훈련이 끝나면 25개의 모델 중에서 검증점수가 가장 높은 모델의 매개변수 조합으로 전체 훈련세트에서 자동으로 다시 모델을 훈련함 - 이 모델은 gs객체의 best_estimator_에 저장되어있음
dt = gs.best_estimator_
print(dt.score(train_input, train_target)) #0.9615162593804117

# 최적의 매개변수(하이퍼파라미터)는 best_params_ 속성에 저장되어있음
print(gs.best_params_) #{'min_impurity_decrease': 0.0001}

# 각 매개변수에서 수행한 교차검증의 평균점수
print(gs.cv_results_['mean_test_score'])  #[0.86819297 0.86453617 0.86492226 0.86780891 0.86761605]

# argmax()함수를 사용하여 교차검증 평균점수 중 가장 큰 값의 인덱스 추출, 그 다음 이 인덱스를 사용해 params키에 저장된 매개변수 출력
best_index = np.argmax(gs.cv_results_['mean_test_score'])
print(gs.cv_results_['params'][best_index])  #{'min_impurity_decrease': 0.0001}
```
#### 정리하면 ... 1) 탐색할 매개변수 지정 2) 훈련세트에서 그리드서치를 수행해 최상의 평균 검증 점수가 나오는 매개변수 조합 찾기 3) 그리드서치는 최상의 매개변수에서 전체 훈련 세트를 사용해 최종 모델을 훈련함      

더 복잡한 매개변수 조합을 탐색해보자.       
```python
params = {'min_impurity_decrease': np.arange(0.0001, 0.001, 0.0001), # 0.0001에서 시작하여 0.001까지 0.0001씩 증가
          'max_depth': range(5, 20, 1),
          'min_samples_split': range(2, 100, 10)
          }
# min_impurity_decrease은 9개(end값은 포함이 안되므로), max_depth 15개, min_samples_split 10개로 이 매개변수로 수행할 교차검증횟수는 9x15x10= 1350개이다. 기본 5-폴드교차검증을 수행하므로 만들어지는 모델의 수는 6750개이다.

#그리드서치 수행
gs = GridSearchCV(DecisionTreeClassifier(random_state=42), params, n_jobs=-1)
gs.fit(train_input, train_target)

#최상의 매개변수 조합 확인
print(gs.best_params_) # {'max_depth': 14, 'min_impurity_decrease': 0.0004, 'min_samples_split': 12}
#최상의 교차검증 점수 확인
print(np.max(gs.cv_results_['mean_test_score'])) # 0.8683865773302731
```
      
**랜덤서치**: 매개변수 값이 수치형(연속적인 실숫값)이라면, 탐색할 값을 직접 나열하는 것이 아니라, 싸이파이의 확률분포객체를 전달하여 특정 범위 내에서 지정된 횟수만큼 매개변수 후보 값을 샘플링하여 교차 검증을 시도할 수 있다. 
이는 한정된 자원을 최대한 활용하여 효율적으로 하이퍼파라미터 공간을 탐색할 수 있는 아주 좋은 도구이다. 





